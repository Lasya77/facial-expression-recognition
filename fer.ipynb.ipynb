{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":36420,"sourceType":"datasetVersion","datasetId":28577}],"dockerImageVersionId":30673,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-04-02T15:14:40.688114Z","iopub.execute_input":"2024-04-02T15:14:40.688521Z","iopub.status.idle":"2024-04-02T15:14:40.707664Z","shell.execute_reply.started":"2024-04-02T15:14:40.688489Z","shell.execute_reply":"2024-04-02T15:14:40.705368Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"/kaggle/input/fer2013/fer2013.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"\nimport numpy as np\nimport pandas as pd\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.utils import to_categorical\n\n# Load the data\ndata = pd.read_csv('/kaggle/input/fer2013/fer2013.csv')\n\n# Preprocess the data\nX = data['pixels'].apply(lambda x: np.array(x.split(), dtype=np.float32)).values\ny = data['emotion'].values\n\n# Convert pixels to grayscale images\nX = np.array([x.reshape(48, 48) for x in X])\n\n# Split the data into train and test sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Reshape the data to have the expected 4D shape for ImageDataGenerator\nX_train = X_train.reshape(-1, 48, 48, 1)\nX_test = X_test.reshape(-1, 48, 48, 1)\n\n# Preprocess the data using ImageDataGenerator\ndatagen = ImageDataGenerator(rescale=1./255)\ndatagen.fit(X_train)\n\n# Convert labels to one-hot encoding\ny_train = to_categorical(y_train, num_classes=7)\ny_test = to_categorical(y_test, num_classes=7)\n","metadata":{"execution":{"iopub.status.busy":"2024-04-02T15:19:01.973047Z","iopub.execute_input":"2024-04-02T15:19:01.973447Z","iopub.status.idle":"2024-04-02T15:19:26.936674Z","shell.execute_reply.started":"2024-04-02T15:19:01.973417Z","shell.execute_reply":"2024-04-02T15:19:26.935460Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n\n# Load the data\ndata = pd.read_csv('../input/fer2013/fer2013.csv')\n\n# Preprocess the data\nX = data['pixels'].apply(lambda x: np.array(x.split(), dtype=np.float32)).values\ny = data['emotion'].values\n\n# Convert pixels to grayscale images\nX = np.array([x.reshape(48, 48) for x in X])\n\n# Split the data into train and test sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Reshape the data to have the expected 4D shape\nX_train = X_train.reshape(-1, 48, 48, 1)\nX_test = X_test.reshape(-1, 48, 48, 1)\n\n# Preprocess the data\nX_train = X_train.astype('float32') / 255.0\nX_test = X_test.astype('float32') / 255.0\n\n# Convert labels to one-hot encoding\ny_train = to_categorical(y_train, num_classes=7)\ny_test = to_categorical(y_test, num_classes=7)\n\n# Build the CNN model\nmodel = Sequential([\n    Conv2D(32, (3, 3), activation='relu', input_shape=(48, 48, 1)),\n    MaxPooling2D((2, 2)),\n    Conv2D(64, (3, 3), activation='relu'),\n    MaxPooling2D((2, 2)),\n    Flatten(),\n    Dense(128, activation='relu'),\n    Dropout(0.5),\n    Dense(7, activation='softmax')\n])\n\n# Compile the model\nmodel.compile(optimizer='adam',\n              loss='categorical_crossentropy',\n              metrics=['accuracy'])\n\n# Train the model\nepochs = 20\nbatch_size = 64\nmodel.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, validation_data=(X_test, y_test))\n","metadata":{"execution":{"iopub.status.busy":"2024-04-02T15:42:46.913370Z","iopub.execute_input":"2024-04-02T15:42:46.913889Z","iopub.status.idle":"2024-04-02T16:04:50.874934Z","shell.execute_reply.started":"2024-04-02T15:42:46.913849Z","shell.execute_reply":"2024-04-02T16:04:50.873622Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/src/layers/convolutional/base_conv.py:99: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n  super().__init__(\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/20\n\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 97ms/step - accuracy: 0.2774 - loss: 1.7768 - val_accuracy: 0.4143 - val_loss: 1.5218\nEpoch 2/20\n\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 98ms/step - accuracy: 0.4047 - loss: 1.5329 - val_accuracy: 0.4533 - val_loss: 1.4369\nEpoch 3/20\n\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 97ms/step - accuracy: 0.4402 - loss: 1.4393 - val_accuracy: 0.4695 - val_loss: 1.3831\nEpoch 4/20\n\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 97ms/step - accuracy: 0.4753 - loss: 1.3714 - val_accuracy: 0.4985 - val_loss: 1.3397\nEpoch 5/20\n\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 98ms/step - accuracy: 0.4912 - loss: 1.3334 - val_accuracy: 0.5045 - val_loss: 1.3040\nEpoch 6/20\n\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 97ms/step - accuracy: 0.5094 - loss: 1.2795 - val_accuracy: 0.5050 - val_loss: 1.2950\nEpoch 7/20\n\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 98ms/step - accuracy: 0.5201 - loss: 1.2500 - val_accuracy: 0.5036 - val_loss: 1.2985\nEpoch 8/20\n\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 97ms/step - accuracy: 0.5311 - loss: 1.2177 - val_accuracy: 0.5213 - val_loss: 1.2728\nEpoch 9/20\n\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 97ms/step - accuracy: 0.5533 - loss: 1.1803 - val_accuracy: 0.5269 - val_loss: 1.2533\nEpoch 10/20\n\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 98ms/step - accuracy: 0.5626 - loss: 1.1320 - val_accuracy: 0.5281 - val_loss: 1.2481\nEpoch 11/20\n\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 98ms/step - accuracy: 0.5733 - loss: 1.1060 - val_accuracy: 0.5330 - val_loss: 1.2449\nEpoch 12/20\n\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 97ms/step - accuracy: 0.5936 - loss: 1.0535 - val_accuracy: 0.5311 - val_loss: 1.2541\nEpoch 13/20\n\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 98ms/step - accuracy: 0.6067 - loss: 1.0193 - val_accuracy: 0.5312 - val_loss: 1.2704\nEpoch 14/20\n\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 97ms/step - accuracy: 0.6146 - loss: 0.9930 - val_accuracy: 0.5332 - val_loss: 1.2646\nEpoch 15/20\n\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 99ms/step - accuracy: 0.6295 - loss: 0.9723 - val_accuracy: 0.5293 - val_loss: 1.2714\nEpoch 16/20\n\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 97ms/step - accuracy: 0.6427 - loss: 0.9322 - val_accuracy: 0.5333 - val_loss: 1.2909\nEpoch 17/20\n\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 101ms/step - accuracy: 0.6462 - loss: 0.9257 - val_accuracy: 0.5357 - val_loss: 1.2963\nEpoch 18/20\n\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 97ms/step - accuracy: 0.6566 - loss: 0.8845 - val_accuracy: 0.5320 - val_loss: 1.3274\nEpoch 19/20\n\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 98ms/step - accuracy: 0.6658 - loss: 0.8628 - val_accuracy: 0.5364 - val_loss: 1.3441\nEpoch 20/20\n\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 97ms/step - accuracy: 0.6780 - loss: 0.8303 - val_accuracy: 0.5361 - val_loss: 1.3515\n","output_type":"stream"},{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"<keras.src.callbacks.history.History at 0x7b83771af5b0>"},"metadata":{}}]}]}